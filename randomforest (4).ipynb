{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1942970,"sourceType":"datasetVersion","datasetId":1159053},{"sourceId":5306083,"sourceType":"datasetVersion","datasetId":3084682}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport librosa\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Feature extraction function\ndef extract_features(fake_root_dirs, real_root_dir, max_length=500):\n    features = []\n    labels = []\n    \n    def process_audio_file(file_path, label):\n        try:\n            # Load audio file\n            audio, _ = librosa.load(file_path, sr=16000)\n            # Extract features (Mel-Frequency Cepstral Coefficients)\n            mfccs = librosa.feature.mfcc(y=audio, sr=16000, n_mfcc=40)\n            # Pad or trim to the fixed length\n            if mfccs.shape[1] < max_length:\n                mfccs = np.pad(mfccs, ((0, 0), (0, max_length - mfccs.shape[1])), mode='constant')\n            else:\n                mfccs = mfccs[:, :max_length]\n            features.append(mfccs)\n            labels.append(label)\n        except Exception as e:\n            print(f\"Error with file: {file_path} -> {str(e)}\")\n\n    # Process fake files from multiple directories\n    for fake_root_dir in fake_root_dirs:\n        for file in os.listdir(fake_root_dir):\n            file_path = os.path.join(fake_root_dir, file)\n            process_audio_file(file_path, 1)  # Label 1 for fake\n\n    # Process real files\n    for file in os.listdir(real_root_dir):\n        file_path = os.path.join(real_root_dir, file)\n        process_audio_file(file_path, 0)  # Label 0 for real\n\n    return np.array(features), np.array(labels)\n\n# Specify fake and real directories\nfake_root_dirs = [\n    '/kaggle/input/wavefake-test/generated_audio/ljspeech_melgan',\n    '/kaggle/input/wavefake-test/generated_audio/ljspeech_melgan_large',\n    '/kaggle/input/wavefake-test/generated_audio/ljspeech_waveglow'\n]\nreal_root_dir = '/kaggle/input/the-lj-speech-dataset/LJSpeech-1.1/wavs'\n\n# Extract features for fake and real audio\nx, y = extract_features(fake_root_dirs, real_root_dir)\n\n# Flatten the 2D MFCC arrays for Random Forest (Random Forest expects 2D input)\nx = x.reshape(x.shape[0], -1)\n\n# Split the data with 30% for testing\nxtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.3, random_state=42)\n\n# Initialize Random Forest classifier\nmodel = RandomForestClassifier(n_estimators=100, max_depth=6, random_state=42)\n\n# Train the model\nmodel.fit(xtrain, ytrain)\n\n# Predict on the test set\nypred = model.predict(xtest)\n\n# Evaluate the model\naccuracy = accuracy_score(ytest, ypred)\nprint(f\"Accuracy: {accuracy:.4f}\")\n\n# Detailed classification report\nprint(classification_report(ytest, ypred))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-18T15:02:51.948653Z","iopub.execute_input":"2024-10-18T15:02:51.949705Z","iopub.status.idle":"2024-10-18T15:46:23.437221Z","shell.execute_reply.started":"2024-10-18T15:02:51.949600Z","shell.execute_reply":"2024-10-18T15:46:23.434807Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Accuracy: 0.7517\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00      3904\n           1       0.75      1.00      0.86     11816\n\n    accuracy                           0.75     15720\n   macro avg       0.38      0.50      0.43     15720\nweighted avg       0.56      0.75      0.65     15720\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"import joblib  # Ensure joblib is imported# Save the trained model using joblib\njoblib.dump(model, '/kaggle/working/random_forest_model.pkl')","metadata":{"execution":{"iopub.status.busy":"2024-10-18T15:56:56.489312Z","iopub.execute_input":"2024-10-18T15:56:56.489817Z","iopub.status.idle":"2024-10-18T15:56:56.581860Z","shell.execute_reply.started":"2024-10-18T15:56:56.489771Z","shell.execute_reply":"2024-10-18T15:56:56.580540Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"['/kaggle/working/random_forest_model.pkl']"},"metadata":{}}]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport librosa\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nimport gc\n\n# Feature extraction function with log-mel spectrograms\ndef extract_features(fake_root_dirs, real_root_dir, max_length=300, n_mels=40, sample_rate=8000, batch_size=32):\n    features = []\n    labels = []\n    \n    def process_audio_file(file_path, label):\n        try:\n            # Load audio file\n            audio, _ = librosa.load(file_path, sr=sample_rate)\n            # Extract log-mel spectrogram\n            mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_mels=n_mels)\n            log_mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n            # Pad or trim to the fixed length\n            if log_mel_spectrogram.shape[1] < max_length:\n                log_mel_spectrogram = np.pad(log_mel_spectrogram, ((0, 0), (0, max_length - log_mel_spectrogram.shape[1])), mode='constant')\n            else:\n                log_mel_spectrogram = log_mel_spectrogram[:, :max_length]\n            features.append(log_mel_spectrogram)\n            labels.append(label)\n        except Exception as e:\n            print(f\"Error with file: {file_path} -> {str(e)}\")\n\n    # Process fake files from multiple directories in batches\n    for fake_root_dir in fake_root_dirs:\n        files = os.listdir(fake_root_dir)\n        for i in range(0, len(files), batch_size):\n            batch_files = files[i:i + batch_size]\n            for file in batch_files:\n                file_path = os.path.join(fake_root_dir, file)\n                process_audio_file(file_path, 1)  # Label 1 for fake\n\n    # Process real files in batches\n    real_files = os.listdir(real_root_dir)\n    for i in range(0, len(real_files), batch_size):\n        batch_files = real_files[i:i + batch_size]\n        for file in batch_files:\n            file_path = os.path.join(real_root_dir, file)\n            process_audio_file(file_path, 0)  # Label 0 for real\n\n    # Convert features and labels to numpy arrays\n    return np.array(features), np.array(labels)\n\n# Specify fake and real directories\nfake_root_dirs = [\n    '/kaggle/input/wavefake-test/generated_audio/ljspeech_melgan',\n    '/kaggle/input/wavefake-test/generated_audio/ljspeech_melgan_large',\n    '/kaggle/input/wavefake-test/generated_audio/ljspeech_waveglow'\n]\nreal_root_dir = '/kaggle/input/the-lj-speech-dataset/LJSpeech-1.1/wavs'\n\n# Extract features for fake and real audio\nx, y = extract_features(fake_root_dirs, real_root_dir)\n\n# Flatten the 2D log-mel spectrogram arrays for Random Forest\nx = x.reshape(x.shape[0], -1)\n\n# Split the data with 30% for testing\nxtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.3, random_state=42)\n\n# Initialize Random Forest classifier\nmodel = RandomForestClassifier(n_estimators=100, max_depth=6, random_state=42)\n\n# Train the model\nmodel.fit(xtrain, ytrain)\n\n# Predict on the test set\nypred = model.predict(xtest)\n\n# Evaluate the model\naccuracy = accuracy_score(ytest, ypred)\nprint(f\"Accuracy: {accuracy:.4f}\")\n\n# Detailed classification report\nprint(classification_report(ytest, ypred))\n\n# Free up memory\ngc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-19T13:34:25.058262Z","iopub.execute_input":"2024-10-19T13:34:25.059217Z","iopub.status.idle":"2024-10-19T13:57:38.111886Z","shell.execute_reply.started":"2024-10-19T13:34:25.059162Z","shell.execute_reply":"2024-10-19T13:57:38.110692Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Accuracy: 0.7517\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00      3904\n           1       0.75      1.00      0.86     11816\n\n    accuracy                           0.75     15720\n   macro avg       0.38      0.50      0.43     15720\nweighted avg       0.56      0.75      0.65     15720\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"import joblib  # Ensure joblib is imported# Save the trained model using joblib\njoblib.dump(model, '/kaggle/working/random_forest_model.pkl')","metadata":{"execution":{"iopub.status.busy":"2024-10-19T13:58:48.511852Z","iopub.execute_input":"2024-10-19T13:58:48.513056Z","iopub.status.idle":"2024-10-19T13:58:48.579520Z","shell.execute_reply.started":"2024-10-19T13:58:48.512977Z","shell.execute_reply":"2024-10-19T13:58:48.578319Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"['/kaggle/working/random_forest_model.pkl']"},"metadata":{}}]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport librosa\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nimport gc\n\n# Data augmentation function\ndef add_noise(audio, noise_factor=0.005):\n    noise = np.random.randn(len(audio))\n    augmented_data = audio + noise_factor * noise\n    return np.clip(augmented_data, -1.0, 1.0)\n\n# Feature extraction function with log-mel spectrograms\ndef extract_features(fake_root_dirs, real_root_dir, max_length=300, n_mels=40, sample_rate=8000, batch_size=32):\n    features = []\n    labels = []\n    \n    def process_audio_file(file_path, label):\n        try:\n            # Load audio file\n            audio, _ = librosa.load(file_path, sr=sample_rate)\n            audio = add_noise(audio)  # Add noise for augmentation\n            \n            # Extract log-mel spectrogram\n            mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_mels=n_mels)\n            log_mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n\n            # Pad or trim to the fixed length\n            if log_mel_spectrogram.shape[1] < max_length:\n                log_mel_spectrogram = np.pad(log_mel_spectrogram, ((0, 0), (0, max_length - log_mel_spectrogram.shape[1])), mode='constant')\n            else:\n                log_mel_spectrogram = log_mel_spectrogram[:, :max_length]\n            \n            features.append(log_mel_spectrogram)\n            labels.append(label)\n        except Exception as e:\n            print(f\"Error with file: {file_path} -> {str(e)}\")\n\n    # Process fake files from multiple directories in batches\n    for fake_root_dir in fake_root_dirs:\n        files = os.listdir(fake_root_dir)\n        for i in range(0, len(files), batch_size):\n            batch_files = files[i:i + batch_size]\n            for file in batch_files:\n                file_path = os.path.join(fake_root_dir, file)\n                process_audio_file(file_path, 1)  # Label 1 for fake\n\n    # Process real files in batches\n    real_files = os.listdir(real_root_dir)\n    for i in range(0, len(real_files), batch_size):\n        batch_files = real_files[i:i + batch_size]\n        for file in batch_files:\n            file_path = os.path.join(real_root_dir, file)\n            process_audio_file(file_path, 0)  # Label 0 for real\n\n    return np.array(features), np.array(labels)\n\n# Specify fake and real directories\nfake_root_dirs = [\n    '/kaggle/input/wavefake-test/generated_audio/ljspeech_melgan',\n    '/kaggle/input/wavefake-test/generated_audio/ljspeech_melgan_large',\n    '/kaggle/input/wavefake-test/generated_audio/ljspeech_waveglow'\n]\nreal_root_dir = '/kaggle/input/the-lj-speech-dataset/LJSpeech-1.1/wavs'\n\n# Extract features for fake and real audio\nx, y = extract_features(fake_root_dirs, real_root_dir)\n\n# Flatten the 2D log-mel spectrogram arrays for Random Forest\nx = x.reshape(x.shape[0], -1)\n\n# Split the data with 30% for testing\nxtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.3, random_state=42)\n\n# Initialize Random Forest classifier\nmodel = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)  # Adjusted parameters\n\n# Train the model\nmodel.fit(xtrain, ytrain)\n\n# Predict on the test set\nypred = model.predict(xtest)\n\n# Evaluate the model\naccuracy = accuracy_score(ytest, ypred)\nprint(f\"Accuracy: {accuracy:.4f}\")\n\n# Detailed classification report\nprint(classification_report(ytest, ypred))\n\n# Free up memory\ngc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-19T14:00:50.741153Z","iopub.execute_input":"2024-10-19T14:00:50.743665Z","iopub.status.idle":"2024-10-19T14:31:53.456547Z","shell.execute_reply.started":"2024-10-19T14:00:50.743536Z","shell.execute_reply":"2024-10-19T14:31:53.455033Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Accuracy: 0.7513\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00      3904\n           1       0.75      1.00      0.86     11816\n\n    accuracy                           0.75     15720\n   macro avg       0.38      0.50      0.43     15720\nweighted avg       0.56      0.75      0.64     15720\n\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"54"},"metadata":{}}]},{"cell_type":"code","source":"import joblib  # Ensure joblib is imported# Save the trained model using joblib\njoblib.dump(model, '/kaggle/working/random_forest_model.pkl')","metadata":{"execution":{"iopub.status.busy":"2024-10-19T14:32:46.841197Z","iopub.execute_input":"2024-10-19T14:32:46.842057Z","iopub.status.idle":"2024-10-19T14:32:46.995233Z","shell.execute_reply.started":"2024-10-19T14:32:46.841998Z","shell.execute_reply":"2024-10-19T14:32:46.993904Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"['/kaggle/working/random_forest_model.pkl']"},"metadata":{}}]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport librosa\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, classification_report\nimport soundfile as sf\nimport gc\n","metadata":{"execution":{"iopub.status.busy":"2024-10-20T09:02:10.123891Z","iopub.execute_input":"2024-10-20T09:02:10.124888Z","iopub.status.idle":"2024-10-20T09:02:11.077314Z","shell.execute_reply.started":"2024-10-20T09:02:10.124833Z","shell.execute_reply":"2024-10-20T09:02:11.076235Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def add_noise(audio, noise_factor=0.005):\n    noise = np.random.randn(len(audio))\n    augmented_data = audio + noise_factor * noise\n    return np.clip(augmented_data, -1.0, 1.0)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-20T09:02:16.000297Z","iopub.execute_input":"2024-10-20T09:02:16.001515Z","iopub.status.idle":"2024-10-20T09:02:16.007781Z","shell.execute_reply.started":"2024-10-20T09:02:16.001456Z","shell.execute_reply":"2024-10-20T09:02:16.006492Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def preprocess_audio_file(file_path, sample_rate=8000):  # Reduced sample rate\n    try:\n        if os.path.getsize(file_path) == 0:  # Skip 0-bit files\n            return None\n        audio, sr = sf.read(file_path)\n        if len(audio) < sample_rate:  # Zero-pad if less than sample_rate\n            audio = np.pad(audio, (0, sample_rate - len(audio)), mode='constant')\n        return audio\n    except Exception as e:\n        print(f\"Error with file: {file_path} -> {str(e)}\")\n        return None\n","metadata":{"execution":{"iopub.status.busy":"2024-10-20T09:02:19.438995Z","iopub.execute_input":"2024-10-20T09:02:19.439394Z","iopub.status.idle":"2024-10-20T09:02:19.446251Z","shell.execute_reply.started":"2024-10-20T09:02:19.439358Z","shell.execute_reply":"2024-10-20T09:02:19.445154Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Extract features\ndef extract_features_combined(fake_root_dirs, real_root_dir, max_length=300, n_mels=40, sample_rate=8000, batch_size=16):\n    features = []\n    labels = []\n\n    def process_audio_file(file_path, label):\n        audio = preprocess_audio_file(file_path, sample_rate)\n        if audio is None:  # Skip invalid or empty files\n            return\n\n        # Add noise for data augmentation\n        audio = add_noise(audio)\n\n        # Extract features\n        mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_mels=n_mels)\n        log_mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n        spectrogram = np.abs(librosa.stft(audio))\n        chroma = librosa.feature.chroma_stft(y=audio, sr=sample_rate)\n        \n        # Adjusted parameters for spectral_contrast\n        spectral_contrast = librosa.feature.spectral_contrast(y=audio, sr=sample_rate, n_bands=4, fmin=50.0)\n\n        # Padding or trimming the features to match max_length\n        def pad_or_trim(feature):\n            if feature.shape[1] < max_length:\n                return np.pad(feature, ((0, 0), (0, max_length - feature.shape[1])), mode='constant')\n            else:\n                return feature[:, :max_length]\n\n        log_mel_spectrogram = pad_or_trim(log_mel_spectrogram)\n        spectrogram = pad_or_trim(spectrogram)\n        chroma = pad_or_trim(chroma)\n        spectral_contrast = pad_or_trim(spectral_contrast)\n\n        # Concatenate all features\n        combined_features = np.concatenate((log_mel_spectrogram, spectrogram, chroma, spectral_contrast), axis=0)\n        features.append(combined_features.astype(np.float32))  # Use float32\n        labels.append(label)\n\n    # Process fake files from multiple directories\n    for fake_root_dir in fake_root_dirs:\n        files = list(set(os.listdir(fake_root_dir)))  # Remove duplicates\n        for i in range(0, len(files), batch_size):\n            batch_files = files[i:i + batch_size]\n            for file in batch_files:\n                file_path = os.path.join(fake_root_dir, file)\n                process_audio_file(file_path, 1)  # Label 1 for fake\n\n    # Process real files\n    real_files = list(set(os.listdir(real_root_dir)))  # Remove duplicates\n    for i in range(0, len(real_files), batch_size):\n        batch_files = real_files[i:i + batch_size]\n        for file in batch_files:\n            file_path = os.path.join(real_root_dir, file)\n            process_audio_file(file_path, 0)  # Label 0 for real\n\n    return np.array(features), np.array(labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-20T09:05:13.811638Z","iopub.execute_input":"2024-10-20T09:05:13.812599Z","iopub.status.idle":"2024-10-20T09:05:13.824959Z","shell.execute_reply.started":"2024-10-20T09:05:13.812553Z","shell.execute_reply":"2024-10-20T09:05:13.823902Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def train_and_evaluate_model(x, y):\n    # Flatten the features\n    x = x.reshape(x.shape[0], -1)\n\n    # Normalize data\n    scaler = StandardScaler()\n    x = scaler.fit_transform(x)\n\n    # Split data\n    xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.3, random_state=42)\n\n    # Define model and parameter grid\n    param_dist = {\n        'n_estimators': [100, 200],\n        'max_depth': [None, 10],\n        'min_samples_split': [2, 5],\n        'min_samples_leaf': [1, 2]\n    }\n\n    # RandomizedSearchCV\n    random_search = RandomizedSearchCV(RandomForestClassifier(random_state=42), param_distributions=param_dist, n_iter=5, cv=3, n_jobs=-1)\n\n    # Train model\n    random_search.fit(xtrain, ytrain)\n\n    # Get best model\n    best_model = random_search.best_estimator_\n\n    # Predict\n    ypred = best_model.predict(xtest)\n\n    # Evaluate\n    accuracy = accuracy_score(ytest, ypred)\n    print(f\"Accuracy: {accuracy:.4f}\")\n    print(classification_report(ytest, ypred))\n\n    # Free up memory\n    del x, y, xtrain, xtest, ytrain, ytest, ypred, best_model, random_search\n    gc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-20T09:05:19.548790Z","iopub.execute_input":"2024-10-20T09:05:19.549223Z","iopub.status.idle":"2024-10-20T09:05:19.557325Z","shell.execute_reply.started":"2024-10-20T09:05:19.549177Z","shell.execute_reply":"2024-10-20T09:05:19.556225Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # Specify directories\n    fake_root_dirs = [\n        '/kaggle/input/wavefake-test/generated_audio/ljspeech_melgan',\n        '/kaggle/input/wavefake-test/generated_audio/ljspeech_melgan_large',\n        '/kaggle/input/wavefake-test/generated_audio/ljspeech_waveglow'\n    ]\n    real_root_dir = '/kaggle/input/the-lj-speech-dataset/LJSpeech-1.1/wavs'\n\n    # Extract features\n    x, y = extract_features_combined(fake_root_dirs, real_root_dir)\n\n    # Train and evaluate model\n    train_and_evaluate_model(x, y)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-20T09:05:23.968727Z","iopub.execute_input":"2024-10-20T09:05:23.969563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport librosa\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier  # Import Random Forest\nfrom sklearn.metrics import accuracy_score, classification_report\nimport gc\nfrom concurrent.futures import ProcessPoolExecutor\n\n# Function to process a single audio file\ndef process_audio_file(file_info, max_length=100):\n    file_path, label = file_info\n    try:\n        audio, _ = librosa.load(file_path, sr=4000)  # Downsample to 4000 Hz\n        stft = librosa.stft(audio, n_fft=256, hop_length=128)  # Short-Time Fourier Transform\n        spectrogram = np.abs(stft)\n\n        if spectrogram.shape[1] < max_length:\n            spectrogram = np.pad(spectrogram, ((0, 0), (0, max_length - spectrogram.shape[1])), mode='constant')\n        else:\n            spectrogram = spectrogram[:, :max_length]\n\n        return spectrogram.astype(np.float32), label\n    except Exception as e:\n        print(f\"Error with file: {file_path} -> {str(e)}\")\n        return None, None\n\n# Generator to yield audio files and labels\ndef audio_file_generator(fake_root_dirs, real_root_dir):\n    for fake_root_dir in fake_root_dirs:\n        for file in os.listdir(fake_root_dir):\n            file_path = os.path.join(fake_root_dir, file)\n            yield file_path, 1  # Label 1 for fake\n    for file in os.listdir(real_root_dir):\n        file_path = os.path.join(real_root_dir, file)\n        yield file_path, 0  # Label 0 for real\n\n# Feature extraction for spectrogram\ndef extract_spectrogram_features(fake_root_dirs, real_root_dir, max_length=250, max_workers=4):\n    features = []\n    labels = []\n    total_files = sum(len(os.listdir(d)) for d in fake_root_dirs) + len(os.listdir(real_root_dir))\n\n    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n        results = list(tqdm(executor.map(process_audio_file, \n                                          audio_file_generator(fake_root_dirs, real_root_dir)), \n                            total=total_files, desc='Processing audio files'))\n\n    for spectrogram, label in results:\n        if spectrogram is not None:\n            features.append(spectrogram)\n            labels.append(label)\n\n    del results\n    gc.collect()\n\n    return np.array(features), np.array(labels)\n\n# Specify fake and real directories\nfake_root_dirs = [\n    '/kaggle/input/wavefake-test/generated_audio/ljspeech_melgan',\n    '/kaggle/input/wavefake-test/generated_audio/ljspeech_melgan_large',\n    '/kaggle/input/wavefake-test/generated_audio/ljspeech_waveglow'\n]\nreal_root_dir = '/kaggle/input/the-lj-speech-dataset/LJSpeech-1.1/wavs'\n\n# Extract features for spectrogram\nx_spectrogram, y_spectrogram = extract_spectrogram_features(fake_root_dirs, real_root_dir)\n\n# Flatten the 2D spectrogram arrays for Random Forest\nx_spectrogram = x_spectrogram.reshape(x_spectrogram.shape[0], -1)\n\n# Train and evaluate Spectrogram model with Random Forest\nxtrain_s, xtest_s, ytrain_s, ytest_s = train_test_split(x_spectrogram, y_spectrogram, test_size=0.3, random_state=42)\nmodel_spectrogram = RandomForestClassifier(n_estimators=100, max_depth=6, random_state=42)  # Use Random Forest\nmodel_spectrogram.fit(xtrain_s, ytrain_s)\nypred_s = model_spectrogram.predict(xtest_s)\n\n# Evaluate the model\naccuracy_s = accuracy_score(ytest_s, ypred_s)\nprint(f\"Spectrogram Model Accuracy with Random Forest: {accuracy_s:.4f}\")\nprint(classification_report(ytest_s, ypred_s))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-20T12:40:18.635049Z","iopub.execute_input":"2024-10-20T12:40:18.635503Z","iopub.status.idle":"2024-10-20T12:49:57.109490Z","shell.execute_reply.started":"2024-10-20T12:40:18.635461Z","shell.execute_reply":"2024-10-20T12:49:57.107445Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"Processing audio files: 100%|██████████| 52400/52400 [04:56<00:00, 176.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Spectrogram Model Accuracy with Random Forest: 0.8541\n              precision    recall  f1-score   support\n\n           0       1.00      0.41      0.58      3904\n           1       0.84      1.00      0.91     11816\n\n    accuracy                           0.85     15720\n   macro avg       0.92      0.71      0.75     15720\nweighted avg       0.88      0.85      0.83     15720\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import joblib  # Ensure joblib is imported\n\n# Save the trained Random Forest model\njoblib.dump(model_spectrogram, '/kaggle/working/random.pkl')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-20T12:51:44.020116Z","iopub.execute_input":"2024-10-20T12:51:44.020606Z","iopub.status.idle":"2024-10-20T12:51:44.116005Z","shell.execute_reply.started":"2024-10-20T12:51:44.020561Z","shell.execute_reply":"2024-10-20T12:51:44.114451Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"['/kaggle/working/random.pkl']"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}